demo()
install.packages(c('quantmod','ff','foreign','R.matlab'),dependency=T)
suppressPackageStartupMessages(library(tidyverse, dplyr))
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
# Shapiro-Wilk normality test
#H0: data are normally distributed
shapiro.test(ToothGrowth$len) #data are normally distributed
view(ToothGrowth)
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
View(ToothGrowth)
data("ToothGrowth")
head(ToothGrowth)
library(dplyr) # for functions
install.packages("dplyr")
library("dplyr", lib.loc="C:/Users/sclau/anaconda3/envs/rstudio/lib/R/library")
library("dbplyr", lib.loc="C:/Users/sclau/anaconda3/envs/rstudio/lib/R/library")
library(dplyr) # for functions
read_fst(
path,
columns = NULL,
from = 1,
to = NULL,
as.data.table = FALSE,
old_format = FALSE
)
library(dplyr) # for functions
library(dplyr) # for functions
read_fst('late_shipments.fst')
read_fst('late_shipments.fst')
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
shapiro.test(ToothGrowth$len) #data are normally distributed
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
install.packages('ggplot2', dep = TRUE),
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
install.packages('ggplot2', dep = TRUE),
library(ggplot2)
install.packages('ggplot2', dep = TRUE)
install.packages("ggplot2", dep = TRUE)
library(ggplot2)
install.packages('ggplot2')
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2", dependencies=TRUE, type="source")
View(ToothGrowth)
install.packages("ggplot2", dependencies=TRUE)
install.packages('ggplot2')
library(ggplot2)
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
# Shapiro-Wilk normality test
#H0: data are normally distributed
shapiro.test(ToothGrowth$len) #data are normally distributed
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
View(ToothGrowth)
shapiro.test(ToothGrowth$len)
mean(ToothGrowth$len)
t.test(ToothGrowth$len,mu=18)
### one sided t-test
### test if the mean value is equal to a certain number
### H0: true value of mean=18
t.test(ToothGrowth$len,mu=10)
### one sided t-test
### test if the mean value is equal to a certain number
### H0: true value of mean=18
t.test(ToothGrowth$len,mu=18)
install.packages("dplyr")
install.packages("fst")
# Read an FST file
late_shipments <- read_fst("late_shipments.fst")
library(dplyr) # for functions
library(fst)
# Read an FST file
late_shipments <- read_fst("late_shipments.fst")
# Read an FST file
late_shipments <- read_fst("/Users/sclau/Documents/01-upskill/DataCamp/datacamp-notes/Statistics Fundamentals with R.fst")
OJ = ToothGrowth$len[ToothGrowth$supp == 'OJ']
VC = ToothGrowth$len[ToothGrowth$supp == 'VC']
t.test(OJ, VC,
paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(OJ, VC,alternative = "greater",paired = FALSE)
late_shipments <- read_csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
install.pakkages("tidyverse")
install.packages("tidyverse")
# Read an FST file
customer_churn <- read_csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn.csv")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr) # for functions
library(tidyverse)
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("C:\Users\sclau\Documents\01-upskill\DataCamp\datacamp-notes\Statistics Fundamentals with R\telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("\Users\sclau\Documents\01-upskill\DataCamp\datacamp-notes\Statistics Fundamentals with R\telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("C:/Users/sclau/Documents/01-upskill/DataCamp/datacamp-notes/Statistics Fundamentals with R/telecom_customer_churn.csv")
#Ho: The mean Total Revenue is the same for those that Churned and those that Stayed
#Ha: The mean Total Revenue is greater for those that Stayed and those that Churned
#HO:  MuStayed = MuChurned
#Ha:  MuStayed > MuChurned
install.packages("dplyr")
install.packages("tidyverse")
library(dplyr) # for functions
library(tidyverse)
# Read the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
# Install packages
install.packages("dplyr")
install.packages("tidyverse")
install.packages("ggplot2")
library(tidyverse) # for data tidying
#library(dplyr) # for tabular data manipulation
library(ggplot2) # for visualization
getwd()
setwd("C:/Users/sclau/Documents/stats-with-R")
# MEASURES OF CENTER
# Measures of center: These are statistical values that represent the central tendency or average of a dataset, such as the mean, median, or mode.
# Normal distribution: It is a symmetric probability distribution where the majority of data points cluster around the mean, resulting in a bell-shaped curve.
# Skewness: It is a measure of the asymmetry of a distribution, indicating whether the data is skewed to the left (negative skewness) or to the right (positive skewness).
# Symmetric Curve:
#
# Mean: The mean is a measure of center that represents the average value of the data. In a symmetric curve, the mean is equal to the median, as both values lie at the center of the distribution.
# Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. In a symmetric curve, the median is the same as the mean, as both values are located at the center of the distribution.
# Skewed Curve:
#
# Mean: The mean is influenced by extreme values in a skewed curve. If the curve is positively skewed (skewed to the right), the mean is pulled towards the higher values. If the curve is negatively skewed (skewed to the left), the mean is pulled towards the lower values.
# Median: The median is less affected by extreme values in a skewed curve. It represents the middle value, unaffected by the skewness. In a positively skewed curve, the median is usually less than the mean, while in a negatively skewed curve, the median is typically greater than the mean.
# Mean and Median
# Read the pizzas csv file
pizzas <- read.csv("Pizza+Place+Sales/pizza_sales/pizzas.csv")
# Filter for small
small_price <- pizzas %>%
filter(size == 'S')
# Filter for medium
medium_price <- pizzas %>%
filter(size == 'M')
# Filter for medium
large_price <- pizzas %>%
filter(size == 'L')
# Calculate mean and median of price for small pizza
mean(small_price$price)
median(small_price$price)
# Calculate mean and median of price for medium pizza
mean(medium_price$price)
median(medium_price$price)
# Calculate mean and  median of price for large pizza
mean(large_price$price)
median(large_price$price)
pizzas %>%
# Filter for small, medium, large pizzas
filter(size %in% c("S", "M","L")) %>%
# Group by size
group_by(size) %>%
# Get mean_price and median_price
summarize(mean_price = mean(price),
median_price = median(price))
# Mean vs Median
# Read the S&P 500 csv file
sp500 <- read.csv("S&P+500+Stock+Prices+2014-2017.csv/S&P 500 Stock Prices 2014-2017.csv")
# Get the data types of each column
column_types <- sapply(sp500, class)
# Print the data types
print(column_types)
# Convert the character date column to datetime
sp500$date <- as.POSIXct(sp500$date)
# Print the updated dataframe
print(sp500)
sp500 %>%
# Create histogram of price
ggplot(aes(close)) +
geom_histogram()
# Q: How do you thing the mean is compared to the median with the histogram?
sp500 %>%
# Get mean_close and median_close
summarize(mean_close = mean(close),
median_close = median(close))
# A: Mean is greater than the Median because the data is skewed to the right.
# Extreme outliers on the right are pulling the Mean to have a greater value.
# Q: When to use mean and median?
# A:
# Use the mean when you have normally distributed data or when you want to capture the overall average value.
# Use the median when you have skewed data, outliers, or when you want a measure that is less affected by extreme values.
# MEASURES OF SPREAD
# Describes how spread apart or close together the data points are
# Variance - distance from each data point to the mean.
# variance - the sum of the square of each data point distance to the mean, divided by the no. of data points
# ⬆️ variance, ⬆️ spread
# Standard Deviation (SD) - square root of the variance. 2 hours (sd) is easier to understand than 4 hours^s (variance)
# Mean Absolute Deviation (MAD) - Absolute distance of each data point to the mean
# Standard Deviation vs Mean Absolute Deviation
# Similar, but not the same
# - SD squares distances, penalizes longer distances more than shorter ones
# - MAD penalizes each distance equally
# One is not better, but SD is more commonly used than MAD
# Quartiles - are a way to divide a set of numbers into four equal parts.
# Imagine you have a group of people lined up based on their heights.
# The first quartile (Q1) would be the height where a quarter of the people are shorter than that, and three-quarters are taller.
# The second quartile (Q2) is the middle height, where half of the people are shorter and half are taller.
# The third quartile (Q3) is the height where three-quarters of the people are shorter and one-quarter are taller.
# It's like splitting the line of people into four equal sections to understand the distribution of heights.
# Quantiles - also known ar percentiles, are a generalized version of quartile
# For splitting the data into more pieces or parts
# Interquartile Range (IQR) - Difference of Q3 and Q1 (upper and lower whiskers of the box plot)
# Box plots are used for representing quartiles
# Outliers - Outliers are values that are significantly different from the other values in a dataset.
# They can be much larger or much smaller than the majority of the data points.
# Outliers stand out from the typical pattern of the data.
# They can affect the overall analysis or interpretation of the data.
# It is important to identify and consider outliers separately.
# Quartiles, Quantiles, and Quintiles
# Calculate the quartiles of the closing price
quantile(sp500$close)
# Calculate the six quantiles that split up the closing price data into 5 pieces
quantile(sp500$close, probs = c(0, 0.2, 0.4, 0.6, 0.8, 1))
# Calculate the deciles of the closing price
quantile(sp500$close, probs = seq(0, 1, 0.1))
# Variance and Standard Deviation
# Calculate variance and sd of the closing price for each date
sp500 %>%
group_by(date) %>%
summarize(var_close = var(close),
sd_close = sd(close))
# Create subgraphs for each date: histogram of closing price
ggplot(pizzas, aes(price)) +
# Create a histogram
geom_histogram() +
# Create a separate sub-graph for each closing price
facet_wrap(~ pizza_type_id)
# Calculate total co2_emission per country: emissions_by_country
ave_closing_by_date <- sp500 %>%
group_by(date) %>%
summarize(ave_close = mean(close))
ave_closing_by_date
q1 <- quantile(ave_closing_by_date$ave_close, 0.25)
q3 <- quantile(ave_closing_by_date$ave_close, 0.75)
iqr <- q3 - q1
# Calculate the lower and upper cutoffs for outliers
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
#Finding outliers using IQR
# Calculate average closing per day: ave_closing_by_date
ave_closing_by_date <- sp500 %>%
group_by(date) %>%
summarize(ave_close = mean(close))
ave_closing_by_date
# Compute the first and third quartiles and IQR of total_emission
q1 <- quantile(ave_closing_by_date$ave_close, 0.25)
q3 <- quantile(ave_closing_by_date$ave_close, 0.75)
iqr <- q3 - q1
# Calculate the lower and upper cutoffs for outliers
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
# Filter emissions_by_country to find outliers
ave_closing_by_date %>%
filter(ave_close < lower | ave_close > upper)
# Calculate average closing per day: ave_closing_by_date
ave_closing_by_date <- sp500 %>%
group_by(date) %>%
summarize(ave_close = mean(close))
ave_closing_by_date
# Compute the first and third quartiles and IQR of ave_close
q1 <- quantile(ave_closing_by_date$ave_close, 0.25)
q3 <- quantile(ave_closing_by_date$ave_close, 0.75)
iqr <- q3 - q1
# Calculate the lower and upper cutoffs for outliers
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
# Filter ave_closing_by_date to find outliers
ave_closing_by_date %>%
filter(ave_close < lower | ave_close > upper)
