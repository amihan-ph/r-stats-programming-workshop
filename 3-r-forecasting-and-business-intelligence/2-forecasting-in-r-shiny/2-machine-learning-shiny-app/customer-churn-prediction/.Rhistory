demo()
install.packages(c('quantmod','ff','foreign','R.matlab'),dependency=T)
suppressPackageStartupMessages(library(tidyverse, dplyr))
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
# Shapiro-Wilk normality test
#H0: data are normally distributed
shapiro.test(ToothGrowth$len) #data are normally distributed
view(ToothGrowth)
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
View(ToothGrowth)
data("ToothGrowth")
head(ToothGrowth)
library(dplyr) # for functions
install.packages("dplyr")
library("dplyr", lib.loc="C:/Users/sclau/anaconda3/envs/rstudio/lib/R/library")
library("dbplyr", lib.loc="C:/Users/sclau/anaconda3/envs/rstudio/lib/R/library")
library(dplyr) # for functions
read_fst(
path,
columns = NULL,
from = 1,
to = NULL,
as.data.table = FALSE,
old_format = FALSE
)
library(dplyr) # for functions
library(dplyr) # for functions
read_fst('late_shipments.fst')
read_fst('late_shipments.fst')
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
shapiro.test(ToothGrowth$len) #data are normally distributed
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
install.packages('ggplot2', dep = TRUE),
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
install.packages('ggplot2', dep = TRUE),
library(ggplot2)
install.packages('ggplot2', dep = TRUE)
install.packages("ggplot2", dep = TRUE)
library(ggplot2)
install.packages('ggplot2')
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2", dependencies=TRUE, type="source")
View(ToothGrowth)
install.packages("ggplot2", dependencies=TRUE)
install.packages('ggplot2')
library(ggplot2)
data("ToothGrowth")
head(ToothGrowth)
str(ToothGrowth)
hist(ToothGrowth$len)
# Shapiro-Wilk normality test
#H0: data are normally distributed
shapiro.test(ToothGrowth$len) #data are normally distributed
library(ggplot2)
qplot(supp,len,data=ToothGrowth,
main="Tooth growth of guinea pigs",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
View(ToothGrowth)
shapiro.test(ToothGrowth$len)
mean(ToothGrowth$len)
t.test(ToothGrowth$len,mu=18)
### one sided t-test
### test if the mean value is equal to a certain number
### H0: true value of mean=18
t.test(ToothGrowth$len,mu=10)
### one sided t-test
### test if the mean value is equal to a certain number
### H0: true value of mean=18
t.test(ToothGrowth$len,mu=18)
install.packages("dplyr")
install.packages("fst")
# Read an FST file
late_shipments <- read_fst("late_shipments.fst")
library(dplyr) # for functions
library(fst)
# Read an FST file
late_shipments <- read_fst("late_shipments.fst")
# Read an FST file
late_shipments <- read_fst("/Users/sclau/Documents/01-upskill/DataCamp/datacamp-notes/Statistics Fundamentals with R.fst")
OJ = ToothGrowth$len[ToothGrowth$supp == 'OJ']
VC = ToothGrowth$len[ToothGrowth$supp == 'VC']
t.test(OJ, VC,
paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(OJ, VC,alternative = "greater",paired = FALSE)
late_shipments <- read_csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
install.pakkages("tidyverse")
install.packages("tidyverse")
# Read an FST file
customer_churn <- read_csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("/Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("Telecom_Customer_Churn/telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn.csv")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr) # for functions
library(tidyverse)
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn.csv")
# Read an FST file
customer_churn <- read.csv("telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("C:\Users\sclau\Documents\01-upskill\DataCamp\datacamp-notes\Statistics Fundamentals with R\telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("\Users\sclau\Documents\01-upskill\DataCamp\datacamp-notes\Statistics Fundamentals with R\telecom_customer_churn")
# Read an FST file
customer_churn <- read.csv("C:/Users/sclau/Documents/01-upskill/DataCamp/datacamp-notes/Statistics Fundamentals with R/telecom_customer_churn.csv")
#Ho: The mean Total Revenue is the same for those that Churned and those that Stayed
#Ha: The mean Total Revenue is greater for those that Stayed and those that Churned
#HO:  MuStayed = MuChurned
#Ha:  MuStayed > MuChurned
install.packages("dplyr")
install.packages("tidyverse")
library(dplyr) # for functions
library(tidyverse)
# Read the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
# Install packages
install.packages("dplyr")
install.packages("tidyverse")
install.packages("ggplot2")
library(tidyverse) # for data tidying
sp500 <- read.csv("S&P 500 Stock Prices 2014-2017.csv")
wd <- getwd()
setwd(wd)
# Mean and Median
# Read the S&P 500 csv file
sp500 <- read.csv("S&P 500 Stock Prices 2014-2017.csv")
install.packages("tidyverse")
install.packages("dplyr")
install.packages("ggplot2")
library(tidyverse) # for data tidying
library(dplyr) # for tabular data manipulation
library(ggplot2) # for visualization
wd <- getwd()
setwd(wd)
wd <- getwd()
library(tidyverse) # for data tidying
library(dplyr) # for tabular data manipulation
library(magrittr)
library(ggplot2) # for visualization
library(lubridate) # for handling date fields
library(broom)
# Machine Learning
library(tidymodels)
library(modeltime)
# remotes::install_github("busine")
# Install packages
install.packages("tidyverse")
install.packages("dplyr")
install.packages("magrittr")
install.packages("ggplot2")
install.packages("lubridate")
install.packages("broom")
install.packages("tidymodels")
install.packages("modeltime")
install.packages(c("tidyverse", "dplyr", "magrittr", "ggplot2", "lubridate", "broom", "tidymodels", "modeltime", "modeltime.ensemble", "modeltime.resample", "timetk"))
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(lubridate)
library(broom)
library(tidymodels)
library(modeltime)
remotes::install_github("business-science/modeltime.gluonts")
remotes::install_github("business-science/modeltime.gluonts")
install.packages("modeltime", dependencies = TRUE)
library(modeltime)
shiny::runApp('shinyApps/hsbc')
setwd("C:/Users/sclau/Documents/r-stats-programming-workshop/3-r-forecasting-and-business-intelligence/2-forecasting-in-r-shiny/1-stock-price-forecasting-r-shiny")
wd <- getwd()
setwd("C:/Users/sclau/Documents/r-stats-programming-workshop/3-r-forecasting-and-business-intelligence/2-forecasting-in-r-shiny/2-machine-learning-shiny-app/customer-churn-prediction")
# Load the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
unique_customer_churn <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE)
# Load the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(ucc$Customer.Status, p=0.7, list = FALSE)
# Importing libraries
library(RCurl) # for downloading the iris CSV file
library(randomForest)
library(caret)
# Load the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE)
library(tidyverse)
# Load the customer churn csv file
customer_churn <- read.csv("telecom_customer_churn.csv")
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(ucc$Customer.Status, p=0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
View(customer_churn)
glimse(ucc)
glimpse(ucc)
ucc <- customer_churn %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Churn.Status) %>%
distinct(Customer.ID, .keep_all = TRUE)
ucc <- customer_churn %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
distinct(Customer.ID, .keep_all = TRUE)
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status)
glimpse(ucc)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(ucc$Customer.Status, p=0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
write.csv(TrainingSet, "training.csv")
write.csv(TestingSet, "testing.csv")
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
View(TrainSet)
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
# Building Random forest model
model <- randomForest(Customer. Status ~ ., data = TrainSet, ntree = 500, mtry = 4, importance = TRUE)
# Building Random forest model
model <- randomForest(Customer.Status ~ ., data = TrainSet, ntree = 500, mtry = 4, importance = TRUE)
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
mutate(Customer.Status = factor(Customer.Status, levels = c("Stayed", "Churn", "Joined")))
glimpse(ucc)
View(ucc)
ucc <- customer_churn %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
mutate(Customer.Status = factor(Customer.Status, levels = c("Stayed", "Churned", "Joined")))
glimpse(ucc)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(ucc$Customer.Status, p=0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
write.csv(TrainingSet, "training.csv")
write.csv(TestingSet, "testing.csv")
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
# Building Random forest model
model <- randomForest(Customer.Status ~ ., data = TrainSet, ntree = 500, mtry = 4, importance = TRUE)
ucc <- customer_churn %>%
filter(Customer.Status %in% c("Stayed", "Churned")) %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
mutate(Customer.Status = factor(Customer.Status, levels = c("Churned", "Stayed")))
glimpse(ucc)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(ucc$Customer.Status, p=0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
write.csv(TrainingSet, "training.csv")
write.csv(TestingSet, "testing.csv")
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
# Building Random forest model
model <- randomForest(Customer.Status ~ ., data = TrainSet, ntree = 500, mtry = 3, importance = TRUE)
ucc <- customer_churn %>%
filter(Customer.Status %in% c("Stayed", "Churned")) %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
mutate(Customer.Status = factor(Customer.Status, levels = c("Churned", "Stayed")))
glimpse(ucc)
# Performs stratified random split of the data set
set.seed(123)  # Setting a seed for reproducibility
TrainingIndex <- createDataPartition(ucc$Customer.Status, p = 0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
write.csv(TrainingSet, "training.csv", row.names = FALSE)
write.csv(TestingSet, "testing.csv", row.names = FALSE)
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
# Building Random Forest model
model <- randomForest(Customer.Status ~ ., data = TrainSet, ntree = 500, mtry = 3, importance = TRUE)
glimpse(ucc)
ucc <- customer_churn %>%
filter(Customer.Status %in% c("Stayed", "Churned")) %>%
distinct(Customer.ID, .keep_all = TRUE) %>%
select(Total.Refunds, Total.Extra.Data.Charges, Total.Long.Distance.Charges, Customer.Status) %>%
mutate(Customer.Status = ifelse(Customer.Status == "Churned", 1, 0))
glimpse(ucc)
# Performs stratified random split of the data set
set.seed(123)  # Setting a seed for reproducibility
TrainingIndex <- createDataPartition(ucc$Customer.Status, p = 0.7, list = FALSE)
TrainingSet <- ucc[TrainingIndex,] # Training Set
TestingSet <- ucc[-TrainingIndex,] # Test Set
write.csv(TrainingSet, "training.csv", row.names = FALSE)
write.csv(TestingSet, "testing.csv", row.names = FALSE)
TrainSet <- read.csv("training.csv", header = TRUE)
TrainSet <- TrainSet[,-1]
# Building Random Forest model
model <- randomForest(Customer.Status ~ ., data = TrainSet, ntree = 500, mtry = 3, importance = TRUE)
# Save model to RDS file
saveRDS(model, "model.rds")
library(shiny); runApp('app-numeric.R')
runApp('app-control.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('app-numeric.R')
runApp('~/r-stats-programming-workshop/3-r-forecasting-and-business-intelligence/2-forecasting-in-r-shiny/2-machine-learning-shiny-app/iris-predictor/app-numeric.R')
runApp('app-numeric.R')
library(shiny)
# Read in the RF model
model <- readRDS("model.rds")
# User interface
ui <- fluidPage(
# Page header
headerPanel('Customer Churn Predictor'),
# Input values
sidebarLayout(
sidebarPanel(
tags$label(h3('Input parameters')),
numericInput("Total_Refunds",
label = "Total Refunds",
value = 10),
numericInput("Total_Extra_Data_Charges",
label = "Total Extra Data Charges",
value = 100),
numericInput("Total_Long_Distance_Charges",
label = "Total Long Distance Charges",
value = 15),
actionButton("submitbutton", "Submit",
class = "btn btn-primary")
),
mainPanel(
tags$label(h3('Customer Status')), # Status/Output Text Box
verbatimTextOutput('contents'),
tableOutput('tabledata') # Prediction results table
)
)
)
# Server
server <- function(input, output, session) {
# Input Data
datasetInput <- reactive({
df <- data.frame(
Name = c("Total Refunds",
"Total Extra Data Charges",
"Total Long Distance Charges"),
Value = as.character(c(input$Total.Refunds,
input$Total.Extra.Data.Charges,
input$Total.Long.Distance.Charges)),
stringsAsFactors = FALSE
)
Customer_Satus <- 0
df <- rbind(df, Customer.Status)
input <- transpose(df)
write.table(input,"input.csv", sep=",", quote = FALSE, row.names = FALSE, col.names = FALSE)
test <- read.csv(paste("input", ".csv", sep=""), header = TRUE)
test <- test[-1,]
Output <- data.frame(Prediction=predict(model,test), round(predict(model,test,type="prob"), 3))
print(Output)
})
# Read in the RF model
model <- readRDS("model.rds")
# User interface
ui <- fluidPage(
# Page header
headerPanel('Customer Churn Predictor'),
# Input values
sidebarLayout(
sidebarPanel(
tags$label(h3('Input parameters')),
numericInput("Total_Refunds",
label = "Total Refunds",
value = 10),
numericInput("Total_Extra_Data_Charges",
label = "Total Extra Data Charges",
value = 100),
numericInput("Total_Long_Distance_Charges",
label = "Total Long Distance Charges",
value = 15),
actionButton("submitbutton", "Submit",
class = "btn btn-primary")
),
mainPanel(
tags$label(h3('Customer Status')), # Status/Output Text Box
verbatimTextOutput('contents'),
tableOutput('tabledata') # Prediction results table
)
)
)
# Server
server <- function(input, output, session) {
# Input Data
datasetInput <- reactive({
df <- data.frame(
Name = c("Total Refunds",
"Total Extra Data Charges",
"Total Long Distance Charges"),
Value = as.character(c(input$Total.Refunds,
input$Total.Extra.Data.Charges,
input$Total.Long.Distance.Charges)),
stringsAsFactors = FALSE
)
Customer_Satus <- 0
df <- rbind(df, Customer.Status)
input <- transpose(df)
write.table(input,"input.csv", sep=",", quote = FALSE, row.names = FALSE, col.names = FALSE)
test <- read.csv(paste("input", ".csv", sep=""), header = TRUE)
test <- test[-1,]
Output <- data.frame(Prediction=predict(model,test), round(predict(model,test,type="prob"), 3))
print(Output)
})
# Status/Output Text Box
output$contents <- renderPrint({
if (input$submitbutton > 0) {
isolate("Calculation complete.")
} else {
return("Server is ready for calculation.")
}
})
# Prediction results table
output$tabledata <- renderTable({
if (input$submitbutton > 0) {
isolate(datasetInput())
}
})
}
# Create the shiny app
shinyApp(ui = ui, server = server)
runApp('app-numeric.R')
